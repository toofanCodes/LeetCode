{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## » Reading from Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### » from dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'col1': range(5), 'col2': range(5,10)}\n",
    "\n",
    "type(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "A     0     5\n",
      "B     1     6\n",
      "C     2     7\n",
      "D     3     8\n",
      "E     4     9\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    pd.DataFrame(\n",
    "        data = d, # input the data - mentioning 'data =' is optional... check below cell for alt implementation\n",
    "        index = ['A', 'B', 'C', 'D', 'E'], # optional - default: RangeIndex starts with 0, or you can define the row index values\n",
    "        columns = ['col1', 'col2'], # same as index, if tuple, then the 'key' from key:value pair is going to be the column\n",
    "        dtype = np.int64, # pd.DataFrame only allows for setting one dtype for whole table\n",
    "        copy = True\n",
    "    )\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1    int64\n",
      "col2    int64\n",
      "dtype: object \n",
      "\n",
      "col1             int64\n",
      "col2    string[python]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# alternatively to convert dtypes, we can do this after creation\n",
    "\n",
    "df.astype({'col1':'int64', 'col2': 'string'})\n",
    "\n",
    "print(df.dtypes,f\"\\n\")\n",
    "\n",
    "# or chain it panda creation like\n",
    "\n",
    "df_dtypes = (\n",
    "    pd.DataFrame(d).astype({'col1':'int64', 'col2':'string'})\n",
    ")\n",
    "\n",
    "print(df_dtypes.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### »» dict - to rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_dict() gives more control over how you insert your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1     x  y\n",
      "z2     1  2\n",
      "n1 n2      \n",
      "a  b   1  3\n",
      "   c   2  4\n"
     ]
    }
   ],
   "source": [
    "data = {'index': [('a', 'b'), ('a', 'c')],\n",
    "        'columns': [('x', 1), ('y', 2)],\n",
    "        'data': [[1, 3], [2, 4]],\n",
    "        'index_names': ['n1', 'n2'],\n",
    "        'column_names': ['z1', 'z2']}\n",
    "\n",
    "print(pd.DataFrame.from_dict(data, orient='tight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "A     0     5\n",
      "B     1     6\n",
      "C     2     7\n",
      "D     3     8\n",
      "E     4     9 \n",
      "\n",
      "      0  1  2  3  4\n",
      "col1  0  1  2  3  4\n",
      "col2  5  6  7  8  9\n"
     ]
    }
   ],
   "source": [
    "df_rows = pd.DataFrame.from_dict(\n",
    "    data = d,\n",
    "    orient = 'index'\n",
    ")\n",
    "print(df, f\"\\n\")\n",
    "print(df_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### »» tight dict - Multi-Index df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tightDict = {'index': [\n",
    "                ('Vector', 'type-A'),('Vector', 'type-B'),\n",
    "                ('Square', 'type-C'),('Square', 'type-D')\n",
    "            ],\n",
    "              'columns': [\n",
    "                  ('A', '$'),('A', '#'),\n",
    "                  ('B', '$'),('B', '#'),\n",
    "                  ('C', '$'),('C', '#')\n",
    "              ],\n",
    "              'data': [\n",
    "                  [0, 1, 2, 3, 4, 5],\n",
    "                  [6, 7, 8, 9, 10, 11],\n",
    "                  [12, 13, 14, 15, 16, 17],\n",
    "                  [18, 19, 20, 21, 22, 23]\n",
    "                  ],\n",
    "              'index_names': ['group', 'type'],\n",
    "              'column_names': ['Category', 'Value']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays must be of the same length\n"
     ]
    }
   ],
   "source": [
    "# lets try a direct approach\n",
    "try: \n",
    "    dfRaw = pd.DataFrame.from_dict(tightDict)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   abs  sec\n",
      "0    1    3\n",
      "1    2    4\n",
      "2    3    5\n"
     ]
    }
   ],
   "source": [
    "dictNew = { \n",
    "    'abs': [1,2,3],\n",
    "    'sec': [3,4,5]\n",
    "}\n",
    "\n",
    "dfTry = pd.DataFrame(dictNew) # for a simple dict it works, but not for a tight dict\n",
    "\n",
    "print(dfTry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category        A       B       C    \n",
      "Value           $   #   $   #   $   #\n",
      "group  type                          \n",
      "Vector type-A   0   1   2   3   4   5\n",
      "       type-B   6   7   8   9  10  11\n",
      "Square type-C  12  13  14  15  16  17\n",
      "       type-D  18  19  20  21  22  23\n"
     ]
    }
   ],
   "source": [
    "# hence the usage of orient = 'tight' in from_dict()\n",
    "# if the dict does not have all keys for index, columns, and data; it will throw error - with optional index_names, column_names\n",
    "dfTight = pd.DataFrame.from_dict(\n",
    "    tightDict, orient = 'tight'\n",
    ")\n",
    "\n",
    "print(dfTight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': [('Vector', 'type-A'),\n",
       "  ('Vector', 'type-B'),\n",
       "  ('Square', 'type-C'),\n",
       "  ('Square', 'type-D')],\n",
       " 'columns': [('A', '$'),\n",
       "  ('A', '#'),\n",
       "  ('B', '$'),\n",
       "  ('B', '#'),\n",
       "  ('C', '$'),\n",
       "  ('C', '#')],\n",
       " 'data': [[0, 1, 2, 3, 4, 5],\n",
       "  [6, 7, 8, 9, 10, 11],\n",
       "  [12, 13, 14, 15, 16, 17],\n",
       "  [18, 19, 20, 21, 22, 23]],\n",
       " 'index_names': ['group', 'type'],\n",
       " 'column_names': ['Category', 'Value']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tightDictNew = dfTight.to_dict(orient = 'tight') ## to write back a tight dict\n",
    "\n",
    "tightDictNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### » from lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = [155, 180, 170, 175, 178]\n",
    "weight = [55, 70, 80, 82, 98]\n",
    "names = ['krill', 'sean', 'megh', 'luke', 'brian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### »» list to columns - default approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0\n",
      "krill  155\n",
      "sean   180\n",
      "megh   170\n",
      "luke   175\n",
      "brian  178\n"
     ]
    }
   ],
   "source": [
    "classHeight = pd.DataFrame( # creating from a single list\n",
    "    height, \n",
    "    index = names)\n",
    "\n",
    "print(classHeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       height  weight\n",
      "krill     155      55\n",
      "sean      180      70\n",
      "megh      170      80\n",
      "luke      175      82\n",
      "brian     178      98\n",
      "height    int64\n",
      "weight    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "classPopln = pd.DataFrame( # combining two lists would practically be like converting into a tuple\n",
    "    {'height':height, 'weight': weight},\n",
    "    index = names\n",
    ")\n",
    "\n",
    "print(classPopln)\n",
    "print(classPopln.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### »» using zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(155, 55), (180, 70), (170, 80), (175, 82), (178, 98)] \n",
      "\n",
      "         0   1\n",
      "krill  155  55\n",
      "sean   180  70\n",
      "megh   170  80\n",
      "luke   175  82\n",
      "brian  178  98\n"
     ]
    }
   ],
   "source": [
    "listRows = list(zip(height, weight))\n",
    "print(listRows, f\"\\n\")\n",
    "\n",
    "df_zip = pd.DataFrame(\n",
    "    listRows,\n",
    "    index = names\n",
    ")\n",
    "\n",
    "print(df_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### »» list of lists - rows data into dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          names   dob id\n",
      "Pavuluri  saran  1992  A\n",
      "Singh     karan  1994  B\n",
      "Dayan     maran  2001  C\n"
     ]
    }
   ],
   "source": [
    "### using multidimensional lists\n",
    "\n",
    "classPII = [\n",
    "    [\"saran\", 1992, 'A'],\n",
    "    [\"karan\", 1994, 'B'],\n",
    "    [\"maran\", 2001, 'C']\n",
    "]\n",
    "\n",
    "classPD = pd.DataFrame(\n",
    "    classPII,\n",
    "    columns = [\"names\", \"dob\", \"id\"],\n",
    "    index = [\"Pavuluri\", \"Singh\", \"Dayan\"]\n",
    "    )\n",
    "\n",
    "print(classPD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### »» Multi-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', '$'), ('A', '#'), ('B', '$'), ('B', '#'), ('C', '$'), ('C', '#')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colIndexTuple = [\n",
    "    ('A', '$'), ('A','#'), ('B', \"$\"), ('B', \"#\"), ('C', \"$\"), ('C', \"#\")\n",
    "] # creating an index tuple pair\n",
    "\n",
    "colIndexTuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('A', '$'),\n",
       "            ('A', '#'),\n",
       "            ('B', '$'),\n",
       "            ('B', '#'),\n",
       "            ('C', '$'),\n",
       "            ('C', '#')],\n",
       "           names=['Category', 'value'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colMultiIndex = pd.MultiIndex.from_tuples(\n",
    "    colIndexTuple, names = ['Category', 'value']\n",
    ") # converting the tuple into a multiindex using pd.MultIndex.from_tuples()\n",
    "\n",
    "colMultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5],\n",
       " [6, 7, 8, 9, 10, 11],\n",
       " [12, 13, 14, 15, 16, 17],\n",
       " [18, 19, 20, 21, 22, 23]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = list(range(6))\n",
    "second = list(range(6,12))\n",
    "third = list(range(12,18))\n",
    "fourth = list(range(18,24))\n",
    "\n",
    "mulData = [first, second, third, fourth]\n",
    "\n",
    "mulData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category   A       B       C    \n",
      "value      $   #   $   #   $   #\n",
      "0          0   1   2   3   4   5\n",
      "1          6   7   8   9  10  11\n",
      "2         12  13  14  15  16  17\n",
      "3         18  19  20  21  22  23\n"
     ]
    }
   ],
   "source": [
    "dfMulti = pd.DataFrame(\n",
    "    mulData,\n",
    "    columns = colMultiIndex\n",
    ")\n",
    "\n",
    "print(dfMulti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Vector', 'type-A'),\n",
       " ('Vector', 'type-B'),\n",
       " ('Square', 'type-C'),\n",
       " ('Square', 'type-D')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets add multi-indexing to rows as well\n",
    "\n",
    "rowsTuple = [\n",
    "    ('Vector', 'type-A'), ('Vector', 'type-B'),\n",
    "    ('Square', 'type-C'), ('Square', 'type-D')\n",
    "]\n",
    "\n",
    "rowsTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('Vector', 'type-A'),\n",
       "            ('Vector', 'type-B'),\n",
       "            ('Square', 'type-C'),\n",
       "            ('Square', 'type-D')],\n",
       "           names=['group', 'type'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowMultiIndex = pd.MultiIndex.from_tuples(\n",
    "    rowsTuple,\n",
    "    names = ['group', 'type']\n",
    ")\n",
    "\n",
    "rowMultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category        A       B       C    \n",
      "value           $   #   $   #   $   #\n",
      "group  type                          \n",
      "Vector type-A   0   1   2   3   4   5\n",
      "       type-B   6   7   8   9  10  11\n",
      "Square type-C  12  13  14  15  16  17\n",
      "       type-D  18  19  20  21  22  23\n"
     ]
    }
   ],
   "source": [
    "dfMulti = pd.DataFrame(\n",
    "    mulData,\n",
    "    columns = colMultiIndex,\n",
    "    index = rowMultiIndex\n",
    ")\n",
    "\n",
    "print(dfMulti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': [('Vector', 'type-A'),\n",
       "  ('Vector', 'type-B'),\n",
       "  ('Square', 'type-C'),\n",
       "  ('Square', 'type-D')],\n",
       " 'columns': [('A', '$'),\n",
       "  ('A', '#'),\n",
       "  ('B', '$'),\n",
       "  ('B', '#'),\n",
       "  ('C', '$'),\n",
       "  ('C', '#')],\n",
       " 'data': [[0, 1, 2, 3, 4, 5],\n",
       "  [6, 7, 8, 9, 10, 11],\n",
       "  [12, 13, 14, 15, 16, 17],\n",
       "  [18, 19, 20, 21, 22, 23]],\n",
       " 'index_names': ['group', 'type'],\n",
       " 'column_names': ['Category', 'value']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMulti.to_dict(orient = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### » from list of Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "2",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "766c5dae-555a-4ae0-9b25-0fa8350153d9",
       "rows": [
        [
         "0",
         "101",
         "Alice",
         "Engineering"
        ],
        [
         "1",
         "102",
         "Bob",
         "Marketing"
        ],
        [
         "2",
         "103",
         "Charlie",
         "Engineering"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Alice</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1            2\n",
       "0  101    Alice  Engineering\n",
       "1  102      Bob    Marketing\n",
       "2  103  Charlie  Engineering"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_data = [\n",
    "    (101, 'Alice', 'Engineering'),\n",
    "    (102, 'Bob', 'Marketing'),\n",
    "    (103, 'Charlie', 'Engineering')\n",
    "]\n",
    "\n",
    "dfTuple = pd.DataFrame(tuple_data)\n",
    "\n",
    "dfTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### » Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a rejoinder\n",
    "# List & Array - built in to python [while list is mostly used, opt for it - if there's a need \n",
    "#                                      for memory efficiecnt storage of homogenous numeric type data]\n",
    "\n",
    "# Numpy & Series - packages for data science\n",
    "# Numpy  - multi dimensional                     - integer indexed   \n",
    "#        - homogenous in standard mode           - optimized for numeric computations (mathermatical and scientific)\n",
    "# numpy does allow for structured forms where heterogenity is allowed, but the space & time efficiencies will be compromised\n",
    "\n",
    "# Series - one direcitonal                       - user-defined index \n",
    "#        - heterogenous capable                  - built on top of numpy but addl functionality and flexible indexing add overhead\n",
    "\n",
    "# Series is better for cleaning, filtering, grouping, combining etc... also handles missing data well "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### »» Standard - homogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0    3    4\n",
      "1   33   44\n",
      "2  133  144\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([\n",
    "    [3,4],\n",
    "    [33,44],\n",
    "    [133,144]\n",
    "]) \n",
    "\n",
    "df = pd.DataFrame(\n",
    "    arr,\n",
    "    columns = ['A', 'B']\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### »» Structured - Heterogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1, 'A', '1st attmept'), (2, 'A', '1st attempt'),\n",
       "       (3, 'B', '2nd attempt')],\n",
       "      dtype=[('id', '<i4'), ('grade', '<U3'), ('attempt', '<U20')])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classMarks = np.array(\n",
    "    [\n",
    "        (1, 'A', '1st attmept'),\n",
    "        (2, 'A', '1st attempt'),\n",
    "        (3, 'B', '2nd attempt')\n",
    "    ],\n",
    "    dtype = [\n",
    "        ('id', 'i4'), ('grade', 'U3'), ('attempt', 'U20')\n",
    "    ]\n",
    ")\n",
    "\n",
    "classMarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### » from pandas.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pronouns",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b445c620-7218-4cf4-b748-28687fdb342a",
       "rows": [
        [
         "me",
         "100"
        ],
        [
         "myself",
         "200"
        ],
        [
         "i",
         "300"
        ],
        [
         "her",
         "400"
        ],
        [
         "him",
         "500"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "me        100\n",
       "myself    200\n",
       "i         300\n",
       "her       400\n",
       "him       500\n",
       "Name: pronouns, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodSales = pd.Series(\n",
    "    data = [100,200,300,400,500],\n",
    "    index = ['me', 'myself', 'i', 'her', 'him'],                # default would be RangeIndex, if not defined\n",
    "    name = 'pronouns'\n",
    ")\n",
    "\n",
    "prodSales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pronouns",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b2e484ea-81e5-4467-9607-49ed108959c0",
       "rows": [
        [
         "me",
         "100"
        ],
        [
         "myself",
         "200"
        ],
        [
         "i",
         "300"
        ],
        [
         "her",
         "400"
        ],
        [
         "him",
         "500"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>me</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myself</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>him</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pronouns\n",
       "me           100\n",
       "myself       200\n",
       "i            300\n",
       "her          400\n",
       "him          500"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfProd = pd.DataFrame(                      # bringing pd.Series into a DataFrame\n",
    "    prodSales\n",
    ")\n",
    "\n",
    "dfProd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "newProdSales = pd.Series(\n",
    "    data = [111,222,333,444,555],\n",
    "    index = ['me', 'myself', 'i', 'her', 'him'],                # default would be RangeIndex, if not defined\n",
    "    name = 'xxx'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pronouns",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "xxx",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "665d9a2f-569d-4191-9cf7-9f47abaf2cba",
       "rows": [
        [
         "me",
         "100",
         "111"
        ],
        [
         "myself",
         "200",
         "222"
        ],
        [
         "i",
         "300",
         "333"
        ],
        [
         "her",
         "400",
         "444"
        ],
        [
         "him",
         "500",
         "555"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronouns</th>\n",
       "      <th>xxx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>me</th>\n",
       "      <td>100</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myself</th>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>300</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <td>400</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>him</th>\n",
       "      <td>500</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pronouns  xxx\n",
       "me           100  111\n",
       "myself       200  222\n",
       "i            300  333\n",
       "her          400  444\n",
       "him          500  555"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfProd = pd.concat(\n",
    "    [\n",
    "        dfProd, \n",
    "        newProdSales\n",
    "        ],\n",
    "    axis = 1\n",
    "    )\n",
    "\n",
    "dfProd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## » Reading from files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### » read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "0     1     A\n",
      "1     2     B\n",
      "2     3     C\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "csvData = \"col1, col2\\n1,A\\n2,B\\n3,C\"       # standard separated by ,\n",
    "\n",
    "csvDF = pd.read_csv(StringIO(csvData))\n",
    "\n",
    "print(csvDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "0     1     A\n",
      "1     2     B\n",
      "2     3     C\n"
     ]
    }
   ],
   "source": [
    "csvData = \"col1; col2\\n1;A\\n2;B\\n3;C\"\n",
    "\n",
    "csvDF = pd.read_csv(\n",
    "    StringIO(csvData),\n",
    "    sep = ';'                   # because our data uses ; - like \\t or |\n",
    ")\n",
    "\n",
    "print(csvDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID Category\n",
      "0   1        A\n",
      "1   2        B\n",
      "2   3        C\n"
     ]
    }
   ],
   "source": [
    "noHeaderCSV = \"1,A\\n2,B\\n3,C\"\n",
    "\n",
    "csvDF = pd.read_csv(\n",
    "    StringIO(noHeaderCSV),\n",
    "    header = None,                                  # if data lacks header\n",
    "    names = ['ID', 'Category']                      # if no header, name your own column names\n",
    ")\n",
    "\n",
    "print(csvDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name grade\n",
      "id             \n",
      "1   saran     A\n",
      "2   aishu     X\n",
      "3    durr     X \n",
      "\n",
      "name     object\n",
      "grade    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "IDdata = \"id,name,grade\\n1,saran,A\\n2,aishu,X\\n3,durr,X\"\n",
    "\n",
    "csvDF = pd.read_csv(\n",
    "    StringIO(IDdata),\n",
    "    index_col = 'id'                    # use the available column as index\n",
    ")\n",
    "\n",
    "print(csvDF, \"\\n\")\n",
    "print(csvDF.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         city  popln\n",
      "id                  \n",
      "1     seattle  90009\n",
      "2    portland  80008\n",
      "3   Anchorage  30002 \n",
      "\n",
      "city     object\n",
      "popln     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "cityList = \"\"\"\n",
    "id,city,state,popln\n",
    "1,seattle,WA,90009\n",
    "2,portland,OR,80008\n",
    "3,Anchorage,AK,30002\n",
    "\"\"\"\n",
    "\n",
    "csvDF = pd.read_csv(\n",
    "    StringIO(cityList),\n",
    "    index_col = 'id',                                   \n",
    "    usecols = ['id','city','popln'],                              # lets get only city and popln while using id as index\n",
    "    dtype = {                                                     # set dtypes\n",
    "        'id':'Int8', \n",
    "        'city':str, \n",
    "        'popln': 'int64'\n",
    "        }           \n",
    ")\n",
    "\n",
    "print(csvDF, \"\\n\")\n",
    "print(csvDF.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Notes:\n",
    "\n",
    "Best practices:\n",
    "1. While loading large datasets:  \n",
    "»»» **specifying dtype** is good because it can become an issue in large datasets  \n",
    "»»» **ID's as string** good to take id's as strings rather than int, because something like 09100 would be changed to 9100  \n",
    "»»» **unique strings in column as Category** i.e. say something like {'product category': 'category'}  \n",
    "»»» **load necessary columns**only using usecols = ['a', 'b']  \n",
    "»»» **load a sample set of rows** only using nrows = 1000  \n",
    "»»» **large files in chunks** chunksize = 10000 --> returns 'TextFileReader' iterator that yields each chunk as separate, temporary DataFrame  \n",
    "»»» **parse dates when you load** ex: parse_dates = {'event_data': ['year','month','day']} -- better than .to_datetime() later-on  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### » read_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Job Title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sub Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Job Link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Job Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Saved At",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5c7a3a51-4afe-43a8-a877-f5f327f9b59f",
       "rows": [
        [
         "0",
         "Holman",
         "Business Intelligence Developer II",
         "BIE",
         "Risky",
         "https://www.linkedin.com/jobs/view/4259283922/?alternateChannel=search&refId=MtF5%2Bm2PoeCVZ7l4wpafqA%3D%3D&trackingId=MtF5%2Bm2PoeCVZ7l4wpafqA%3D%3D",
         "About the job\n\nHolman is a family-owned, global automotive services organization anchored by our deeply rooted core values and principles that have enabled us to continue Driving What‚Äôs Right throughout the last century. Our teams deliver the Holman Experience by treating our customers and each other as we would like to be treated, and creating positive, rewarding relationships all around.\n\nThe automotive markets Holman serves include fleet management and leasing; vehicle fabrication and upfitting; component manufacturing and productivity solutions; powertrain distribution and logistics services; commercial and personal insurance and risk management; and retail automotive sales as one of the largest privately owned dealership groups in the United States.\n\nHolman is a forward-thinking organization dedicated to leveraging data-driven insights to fuel innovation and drive business outcomes. We are looking for a passionate and skilled Business Intelligence Developer II to join our team and make an impact in transforming raw data into actionable intelligence using modern platforms like Databricks and Power BI.\n\nJob Summary:\n\nThe Business Intelligence Developer II will be responsible for designing, developing, and maintaining advanced data solutions. This role involves creating pipelines in Databricks for Silver (curated) and Gold (aggregated, high-value) layers of data, developing insightful dashboards in Power BI, and applying Machine Learning (ML) and Artificial Intelligence (AI) techniques to solve complex business problems.\n\nKey Responsibilities:\n\n\nData Transformation and Integration:\nDevelop and maintain data pipelines in Databricks for Silver and Gold layers, ensuring data quality and reliability.\nOptimize data workflows to handle large volumes of structured and unstructured data efficiently.\nPower BI Semantic Model Management:\nDesign and optimize Power BI semantic models, including creating star schemas, managing table relationships, and defining DAX measures to support robust reporting solutions.\nVisualization and Reporting:\nCreate, enhance, and maintain interactive dashboards and reports in Power BI to provide actionable insights to stakeholders.\nCollaborate with business units to gather requirements and ensure dashboards meet user needs.\nML/AI Model Development:\nUse Databricks and other platforms to build and operationalize ML/AI models to enhance decision-making.\nCollaboration:\nWork closely with data engineers, analysts, and business stakeholders to deliver scalable and innovative data solutions.\nParticipate in code reviews, ensure best practices, and contribute to a culture of continuous improvement.\n\n\nQualifications:\n\n\nEducation:\nBachelor‚Äôs degree in Computer Science, Data Analytics, Information Systems, or a related field.\nMasters degree in Analytics preferred but not required.\nExperience:\n3-5 years of experience in business intelligence, data engineering, or a related role.\nProficiency in Databricks (Spark, PySpark) for data processing and transformation.\nStrong expertise in Power BI for semantic model management, dashboarding and visualization.\nExperience building and deploying ML/AI models in Databricks or similar platforms.\nTechnical Skills:\nProficiency in SQL and Python.\nSolid understanding of ETL/ELT pipelines and data warehousing concepts.\nFamiliarity with cloud platforms (e.g., Azure, AWS) and tools like Delta Lake.\nGit, GitHub, and CI/CD practices.\nSoft Skills:\nExcellent problem-solving and analytical skills.\nStrong communication skills, with the ability to translate complex technical concepts into business-friendly language.\nProven ability to work both independently and collaboratively in a fast-paced environment.\n\n\nPreferred Qualifications:\n\n\nCertifications in Power BI, Databricks, or cloud platforms.\nExperience with advanced analytics tools (e.g., TensorFlow, Scikit-learn, AutoML).\nExposure to Agile methodologies and DevOps practices.\n\n\n#REMOTE\n\nAt Holman, we exist to provide rewarding careers and better lives for employees and their families. We hire, train, empower, and reward exceptional people. Our journey is guided by our desire to get it right every time and the acknowledgement that we have an opportunity to be better. To be better, we have to do better, and to do better we must know better. That‚Äôs why we are listening, open to learning new things ‚Äì about ourselves and each other. We will never stop striving for improved diversity, equity, and inclusion because we are successful together when we feel trusted and supported. It‚Äôs The Holman Way.\n\nAt Holman, your total compensation goes beyond your paycheck. To position you for success and provide a rewarding career and better life for you and your family, Holman is proud to offer you the benefits you deserve; including protection against illness, disability, loss of work, or preparation for retirement. Below is a brief overview of the programs available to full-time employees (programs may vary by country or worker type):\n\n\nHealth Insurance\nVision Insurance\nDental Insurance\nLife and Disability Insurance\nFlexible Spending and Health Savings Accounts\nEmployee Assistance Program\n401(k) plan with Company Match\nPaid Time Off (PTO)\nPaid Holidays, Bereavement, and Jury Duty\nPaid Pregnancy/Parental leave\nPaid Military Leave\nTuition Reimbursement\n\n\nBenefits:\n\nRegular Full-Time\n\nWe offer excellent benefits including health, vision, dental, life and disability insurance, and 401(k) with company match. Our time off benefits include Paid Time Off (PTO), paid holidays, bereavement, and jury duty. In addition, we offer paid pregnancy and parental leave, and supplemental paid military leave to eligible employees.\n\nClick here for Washington State benefit information.\n\nTemporary or Part-Time\n\nIn geographic areas with statutory paid sick leave, part-time and temporary employees will receive a paid sick leave benefit that meets the mandated requirements.\n\nClick here for Washington State benefit information.\n\nPay:\n\nEqual Opportunity Employment and Accommodations: \n\nHolman provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n\nIf you are a person with a disability needing assistance with the application process, please contact HR@Holman.com \n\nThis policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",
         "6/30/2025, 2:26:31 AM"
        ],
        [
         "1",
         "The College Board",
         "Data Analyst, AWS Analytics",
         "Analyst",
         "Risky",
         "https://www.linkedin.com/jobs/view/4259283160/?alternateChannel=search&refId=I%2FzyZp%2BPijn%2FV3EmXXd0eg%3D%3D&trackingId=I%2FzyZp%2BPijn%2FV3EmXXd0eg%3D%3D",
         "About the job\n\nCollege Board - Technology Division ‚Äì Exam Config\n\n100% Remote, working core EST hours\n\nAbout The Team\n\nThe College Board‚Äôs Exam Config team is a dynamic group of 12 collaborative, motivated technologists dedicated to implementing essential services that support the lifecycle of student assessments‚Äîfrom registration to score reporting. We continuously seek, experiment with, and utilize innovative technologies to build high-quality products, all with the singular purpose of providing comprehensive assessments to millions of students. As we transition to digital administration for SAT, PSAT, and AP exams, our team explores exciting new opportunities to contribute to initiatives crucial to our mission of clearing a path for all students to own their future.\n\nAbout The Opportunity\n\nAs a Data Analyst, AWS Analytics on the Exam Config team, you are a detail-oriented collaborator and innovator with strong commitment to delivering exceptional quality. In this role, you will play a critical part in supporting data management and conducting root cause analysis to ensure the reliability and accuracy of Exam Config systems. Leveraging your AWS expertise, advanced SQL skills, and strong problem-solving abilities, you will work with complex data sets, automate key processes, and drive efficiency. Your excellent communication and interpersonal skills will enable you to collaborate effectively with cross-functional teams as you help enhance data accuracy and system performance. You are independent and proactive with exceptional problem-solving skills. You are proactive, independent and thrive in a fast-paced, Agile environment‚Äîeager to make a meaningful impact on the digital transformation of SAT, PSAT, and AP exams.\n\nIn This Role, You Will\n\n\nAnalyze data to identify trends, detect anomalies, and uncover opportunities for improvement\nConduct root cause analysis (RCA) of system and data-related issues, documenting findings and recommending solutions\nWrite and execute SQL queries to extract, manipulate, and analyze data from various sources\nUtilize AWS analytics tools (e.g. Athena, Postgres, Redshift) to perform advanced data analysis and generate meaningful reports\nCollaborate with business and technical teams to translate data insights into actionable recommendations\nDevelop and review requirements, data mappings, user stories, and related documentation, clearly communicating to both business and technical team members\nTroubleshoot and resolve production issues by partnering with engineering teams to identify root causes and implement fixes\nFulfill ad hoc data requests while ensuring compliance with governance and security policies\nSupport functional testing efforts by validating data accuracy, system behavior, and process integrity\n\n\n\n\nAbout You\n\nYou have:\n\n\n6+ years of experience in enterprise-wide data management\nAdvanced SQL skills with experience writing complex queries for data extraction and analysis\nHands-on experience with AWS services and analytics tools, including Athena, Redshift/Postgres, DynamoDB, and S3\nProven experience conducting root cause analysis and resolving data and system-related issues\nSkill in working with large, complex datasets to identify patterns, detect inconsistencies, and recommend optimizations\nStrong analytical and problem-solving skills with a keen eye for detail\nExcellent communication and collaboration skills for engaging with technical and business stakeholders\nFamiliarity with functional testing practices and validating data/system behavior\nUnderstanding of Agile methodology and comfort working in a DevOps environment\nProficiency with scripting languages such as Python or Shell scripting\nBachelor‚Äôs degree required; MS or MBA highly desirable\nAuthorization to work in the United States\n\n\n\n\nAbout Our Process\n\n\nApplication review will begin immediately and will continue until the position is filled \nWhile the hiring process may vary, it generally includes: resume and application submission, recruiter phone/video screen, hiring manager interview, performance exercise such as live coding, a panel interview, a conversation with leadership and reference checks. \n\n\n\n\nAbout Our Benefits And Compensation\n\nCollege Board offers a competitive benefits and compensation program that attracts top talent looking to make a difference in education. As a self-sustaining non-profit, we believe in compensating employees equitably in relation to each other, their qualifications, their impact, and the relevant market.\n\nThe hiring range for a new employee in this position is $125,000 to $135,000. Your salary will be carefully determined based on your location, relevant experience, the external labor market, and the pay of College Board employees in similar roles. College Board strives to provide our best offer up front based on this criteria.\n\nYour salary is only one part of all that College Board offers, including but not limited to:\n\n\nA comprehensive package designed to support the well-being of employees and their families and promote education. Our robust benefits package includes health, dental, and vision insurance, generous paid time off, paid parental leave, fertility benefits, pet insurance, tuition assistance, retirement benefits, and more\nRecognition of exceptional performance through annual bonuses, salary growth over time through market increases, and opportunities for merit raises and promotions based on increased scope of responsibility\nA job that matters, a team that cares, and a place to learn, innovate and thrive\n\n\n\n\nYou can expect to have transparent conversations about benefits and compensation with our recruiters throughout your application process.\n\nAbout Our Culture\n\nOur community matters, and we strive to practice and improve our culture daily. Here are some headlines:\n\n\nWe are motivated to positively impact the educational and career trajectories of millions of students a year \nWe prioritize building a diverse and inclusive team where every employee can thrive, and every voice is heard\nWe are a dynamic hybrid team, giving staff members the choice to either be fully remote or hybrid if they live close to a College Board office. Hybrid employees go into offices every Tuesday and Wednesday\nWe welcome staff to join any or all six of our affinity groups: ARISE (Alliance for Asian Retention, Inclusion, Success, and Engagement; DIASPORA (Alliance for Pan-African Success and Achievement); Pride (alliance for LGBTQ+ staff and allies); Resilience (alliance for Native staff and advocates); SALSA (Staff Alliance for Latinx Success and Achievement); and WIN (Women‚Äôs Impact Network)\nWe value learning and growth; we offer formal and informal ways to lead through your superpowers, sharpen your strengths, and meet your development goals\nOur high-performing engineers work with the latest technologies, so you will be constantly learning and sharpening your skills\n\n\n\n\nAbout College Board\n\nCollege Board reaches more than 7 million students a year, helping them navigate the path from high school to college and career. We‚Äôre a mission-driven, not-for-profit membership organization dedicated to excellence in education. Founded 125 years ago, we are committed to clearing a path for all students to own their future. We pioneered programs like the SAT¬Æ and AP¬Æ to expand opportunities for students and help them develop the skills they need. Our BigFuture¬Æ program helps students plan for college, pay for college, and explore careers. Learn more at cb.org.\n\nCollege Board reaches more than 7 million students a year, helping them navigate the path from high school to college and career. We‚Äôre a mission-driven, not-for-profit membership organization dedicated to excellence in education. Founded 125 years ago, we are committed to clearing a path for all students to own their future. We pioneered programs like the SAT¬Æ and AP¬Æ to expand opportunities for students and help them develop the skills they need. Our BigFuture¬Æ program helps students plan for college, pay for college, and explore careers. Learn more at cb.org.\n\nMission\n\nClearing a path for all students to own their future.\n\nClearing a path for all students to own their future.\n\nWhat Guides Us\n\nAt College Board, our work is guided by four Operating Principles, and we seek team members who not only align with these principles but actively live them out in their day-to-day work .\n\n\nPrioritize and Simplify ‚Äì We focus on what matters most, reduce complexity, and move quickly when needed.\nSay and Receive ‚Äì We give and receive feedback candidly and kindly, welcoming growth and healthy debate.\nGo for Greatness ‚Äì We pursue excellence using data, iteration, and bold thinking to raise the bar.\nLead as One College Board ‚Äì We build a culture of trust, inclusion, and shared responsibility for long-term impact.\n\n\n\n\nAt College Board, our work is guided by four Operating Principles, and we seek team members who not only align with these principles but actively live them out in their day-to-day work .\n\n\nPrioritize and Simplify ‚Äì We focus on what matters most, reduce complexity, and move quickly when needed.\nSay and Receive ‚Äì We give and receive feedback candidly and kindly, welcoming growth and healthy debate.\nGo for Greatness ‚Äì We pursue excellence using data, iteration, and bold thinking to raise the bar.\nLead as One College Board ‚Äì We build a culture of trust, inclusion, and shared responsibility for long-term impact.\n\n\n\n\nWe Value and Provide Growth, Recognition, and Purpose\n\nIn addition to a competitive salary and benefits, we offer:\n\n\nAnnual bonuses and opportunities for merit-based raises and promotions\nA mission-driven workplace where your impact matters\nA team that invests in your development and success\n\n\n\n\nIn addition to a competitive salary and benefits, we offer:\n\n\nAnnual bonuses and opportunities for merit-based raises and promotions\nA mission-driven workplace where your impact matters\nA team that invests in your development and success\n\n\n\n\n‚ú®Learn More ‚ú®\n\nLearn more about College Board‚Äôs Operating Principles, Our Remote-first Workplace Policy, Benefits, Recruiting Process and More.\n\nLearn more about College Board‚Äôs Operating Principles, Our Remote-first Workplace Policy, Benefits, Recruiting Process and More.\n\nEEOC statement\n\nCollege Board is proud to be an equal opportunity employer. We‚Äôre committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status.\n\nCollege Board is proud to be an equal opportunity employer. We‚Äôre committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status.",
         "6/30/2025, 2:29:17 AM"
        ],
        [
         "2",
         "AmTrust Financial Services, Inc.",
         "Analytics Analyst II",
         "BIE",
         "Medium",
         "https://www.linkedin.com/jobs/view/4257913602/?alternateChannel=search&refId=QWPIRZN1OuUhIo%2BXhyc3kg%3D%3D&trackingId=QWPIRZN1OuUhIo%2BXhyc3kg%3D%3D",
         "About the job\n\nOverview\n\nAmTrust Financial is seeking a data-driven professional to support reporting and analytics initiatives focused on pricing and submission workflows. This role involves designing and building reports for submission tracking, collaborating with product teams to integrate vendor data, and contributing to continuous improvement through analytics projects.\n\nResponsibilities\n\n\n Submissions Reporting: Design and build reports to track and manage front-end pricing and submission workflow \n Third Party Data: Collaborate with product teams to create and optimize utilization of vendor data \n Continuous Improvement: Learn to leverage more advanced analytics techniquires through adhoc projects and collaborative efforts \n Provide Insight: Deliver actionable information to senior leadership through adhoc reports and projects while owning the full lifecycle of data from query to analysis to reporting \n\n\nQualifications\n\n\n Bachelor's degree. Preference for Data Science, Computer Science, Economics, Business Statistics, Operational Research, or a related quantitative field \n 2+ years experience in R/Python including \n Basic automation and algorithm tasks, reading/writing to excel, API requests \n Data wrangling in tidyverse and/or pandas \n 2+ years experience in SQL \n Good understanding of basic statistical inference and computer science concepts \n Demonstrated ability to learn quickly and apply new ideas \n Comfortable with excel pivot tables &formulas \n Good interpersonal and communication skills \n\nPreferred\n\n\n Comfortable generating wide arange of visuals in either ggplot2 or matplotlib \n Experience with PowerBI or Tableau \n Experience with performing data analysis and generating reports/dashboards \n Experience with any DevOps platform and agile methodology (Azure, etc.) \n Familiarity with predictive modelling, ML & AI applications an advantage \n Prior role at insurance carrier, brokerage, or other pricing/customer-centric analyst \n\n\nWhat We Offer\n\nAmTrust Financial Services offers a competitive compensation package and excellent career advancement opportunities. Our benefits include: Medical & Dental Plans, Life Insurance, including eligible spouses & children, Health Care Flexible Spending, Dependent Care, 401k Savings Plans, Paid Time Off.\n\nAmTrust strives to create a diverse and inclusive culture where thoughts and ideas of all employees are appreciated and respected. This concept encompasses but is not limited to human differences with regard to race, ethnicity, gender, sexual orientation, culture, religion or disabilities.\n\nAmTrust values excellence and recognizes that by embracing the diverse backgrounds, skills, and perspectives of its workforce, it will sustain a competitive advantage and remain an employer of choice. Diversity is a business imperative, enabling us to attract, retain and develop the best talent available. We see diversity as more than just policies and practices. It is an integral part of who we are as a company, how we operate and how we see our future.",
         "6/30/2025, 2:40:56 AM"
        ],
        [
         "3",
         "University of Montana Foundation",
         "Programmer Analyst",
         "Analyst",
         "Low",
         "https://www.linkedin.com/jobs/view/4255252626/?alternateChannel=search&eBP=CwEAAAGXwBjfJwztnmdwkQcNn1FtJPVM1Zkgt4hpMkeNw10-ZF6pKDwkrBmoSaM6gAqcbfslfjCD2CbkOzknAQ2vU9dWjwyCsIseF4ACESqLQ7LjRo605QkmDPH8jvjd1r4MBXxqiaqV0yBgslI0MBCPMjqUCU2e-iKIWb3XhU6vo-rBMPFA3oEvFCs6KX4199qk6Z8pXpDZ-4ud_U4r361o8-YZ_7rUel8S5roT153nQbZOGEX80UKC9Uh5sZSW2384lx9-1yJgiiozNHNwYaaDJWvGZEUTvgB01ag8vyJAJFlljD3GWIe9O_SaNFGaRMiObMz58xFUZyvSxkh9aZkH9fHp9JsI3tLQRu0vZJubK8IVgk30ToZveL3V5zxIGBHLxecQjYh_1UhQA7Gw&refId=ZeLvzLZ2LZ8XkkYGGpYsug%3D%3D&trackingId=u%2FOhXt%2F4yxrZxLBfZ%2BqRLQ%3D%3D&trk=d_flagship3_jobs_discovery_jymbii",
         "About the job\n\nAt the University of Montana Foundation, the lives we change will change the world. We inspire donors to bolster UM‚Äôs mission of providing an accessible, affordable, and world-class education. \n\nWe are committed to maintaining a diverse and inclusive workplace that reflects the people and culture of the University we serve, fostering an environment allowing us to inspire each other to our best work. We act with integrity and respect, and work to create a team where everyone feels valued, respected, and supported. \n\n\n\n\nWhy Work for Us? \n\nRetirement Planning: 403(b) employer contribution of 11%, no employee match required!\nFlexible Work Arrangement: Opportunity for a full remote work arrangement within Montana.\nGenerous Time off Benefits: Team members accrue four weeks of vacation and 12 days of sick leave per year, with an additional 11 days of holiday leave\nFamily Support: Paid parental leave for new parents\nHealth and Wellness: Medical, dental, vision, wellness program, and short-term and long-term disability pay protection benefits\nCareer Advancement: Professional development opportunities.\nCompetitive Pay: Candidates can request the starting pay range by emailing‚ÄØhumanresources@supportum.org \n\n\n\n\nAbout the Role: \n\nThe Programmer Analyst is responsible for all phases of the software development lifecycle including design, construction, testing, maintenance, documentation, upgrades, and retirement. Frequently interacts with users, using iterative development techniques like Agile and Rapid Application Development (RAD)/Joint Application Development (JAD) to achieve the best results for the user and business. Often works independently planning and prioritizing activities to determine methods and techniques used for development and resolving all technical and functional problems associated with assigned projects. \n\n\n\n\nKey Responsibilities: \n\nProvides analysis, design, programming, documentation and support of CRM Advance\nDevelops reporting solutions\nProject planning, tracking, management, and support, including time estimation, project updates, and time tracking\nMaintains effective working relationships with a diverse group of colleagues and end users in a team environment\nParticipates in Agile Scrum meetings and user meetings\n\n\n\n\nIdeal Candidate: \n\nHas excellent written and oral communication skills\nAbility to handle multiple changing priorities in a fast-paced environment\nFive years of progressively responsible systems design and software development experience in an administrative computing environment or demonstrated combination of education and experience\nExperience with a Business Intelligence reporting system such as Power BI, Microsoft Reporting Services (SSRS), Crystal Reports, or Tableau\nHas experience with Dynamics 365, CRM Advance or working in Advancement Services office \nHas experience working in an Agile Scrum development environment\nEnjoys the challenge of problem solving\nCustomer centric\n\n \n\nThe University of Montana Foundation is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request a reasonable accommodation to participate in the recruitment process at the University of Montana Foundation, contact humanresources@supportum.org. All hiring decisions are made without regard to race, color, religion, gender, sexual orientation, gender identity, national origin, age, disability, or veteran status. \n\nAll employment offers are contingent upon successful completion of a criminal background check. \n\n\n\n\nPriority Application Date: \n\nMonday, July 7, 2025. Complete applications received by this date will be guaranteed consideration.\n\n \n\nIf you do not meet all the qualifications of the position, you are still encouraged to apply.",
         "6/30/2025, 3:08:14 AM"
        ],
        [
         "4",
         "Gen",
         "Digital Product Analyst",
         "Analyst",
         "Medium",
         "https://www.linkedin.com/jobs/view/4205437869/?alternateChannel=search&eBP=CwEAAAGXwBjfJyW1jKacT3nqshiaTo7Y3yfmLbsT2d5MtM3R6vXCTLgdzC8rSkw7xkCXVt-LGFNd5DozFSwrl4E0_to7aZsPCOVB7efUdcD8-LzOGSmD93DcugNuva0scA067DFjc2dUFfhRo8ksnMaFB4ZGFfIE-6GaZzDqi3KSJwY75yfbRafitaT2Qy0Bf9qGTZ5qy2o7Rs-BJTbAXoHSSdOlOMK43IOYbK-VI4lKzzJPgbNTVKWp3-3RssMuIBChKioEjteRiPXDYnjeqaN9M8mc67Ne6q2EIJlJXEjkKngIfAvInKBA9VT6JY_hntlJuFKCwZFAUA7FGha44rz677tm191Oki_JmtSPQLxE3_1pkNMPi9Si-Cllpf3y8I7nAjIo4EvLkj5Pu1g5kSDAn3YqS5Gk0HYi17ySredaaEp-ZEJRPq5eEmEKTGkv384FUEyHxRMfx61mNUFYcWQSi3hvEmTCd_8IirUHLJTxY84&refId=ZeLvzLZ2LZ8XkkYGGpYsug%3D%3D&trackingId=Xzlo3yYPvdX8HBOKB%2FvKjA%3D%3D&trk=d_flagship3_jobs_discovery_jymbii",
         "About the job\n\nAbout The Role\n\nWe are hiring Digital Product Analysts across our highly specialized product teams to drive informed decision-making and optimize business strategies in the dynamic digital media space.\n\nAs a critical member of our team, you will analyze complex data sets, identify actionable intelligence, and translate findings into strategic recommendations that propel our organization forward. You will become a subject matter expert to deeply understand the end-to-end workflow, data sets, and goals to enable your ability to recommend improvements, optimizations, and bigger solutions.\n\nHow You‚Äôll Make An Impact\n\n\nStrategize with the embedded team to develop a cohesive and comprehensive understanding of the key drivers of the business, and leverage that understanding to achieve goals and move the company forward.\nIngest and aggregate key performance data, KPIs and operational data sets (for example keywords/groups, ads, bidding, creative assets, etc.) to build structured models and analysis to drive insights and actionable intelligence.\nAnalyze and diagnose website performance, user behavior, traffic trends, and conversion metrics to identify patterns and provide actionable insights to drive growth, optimization, cost-cutting, and performance improvement.\nConceptualize and utilize statistical methods and data visualization techniques to convey a compelling business case for implementing recommendations based on data insights. Begin to build relationships with the Data Science Team for advanced data modeling.\nProactively share insights and strategic recommendations with measurable and sizable business impact, offering data-driven recommendations to optimize pages, improve user experience, and enhance conversion rates, aligning with the goals of multiple business units.\nPartner with the Yield and Data Science teams to drive decision-making via critical, time-sensitive insights about our publisher partners, ad placements, and opportunities to improve KPIs.\nDrive meaningful conversations with Data Engineering and Data Analytics to improve data access, data platform, data flow, and data accuracy.\nPivot quickly and smoothly between high-priority projects and changing business needs based on goals.\nFoster solid working relationships with co-workers, leadership, and stakeholders to develop and maintain alignment in priorities, strategy, and vision across crucial initiatives.\n\n\n\nWhat You‚Äôll Need\n\n\nExperience: 3+ years of relevant work experience analyzing and optimizing website performance, user behavior, traffic patterns, and conversion metrics.\nStrong background in analytics, understanding of concepts like Statistical Significance.\nBA/BS in Mathematics, Statistics, Finance, Marketing, Economics, or a related field.\nExceptionally high standards in communicating the results of analysis clearly and effectively.\nStrong verbal and written communication skills and confidence to deliver technical information succinctly and assertively to non-technical audiences.\nComplex problem-solving and critical thinking skills, along with a solutions-oriented mindset.\nIntermediate knowledge of Excel, including the ability to use formulas, functions, and pivot tables.\n\n\n\nGen is proud to be an equal-opportunity employer, committed to diversity and inclusivity. We base employment decisions on merit, experience, and business needs, without considering race, color, national origin, age, religion, sex, pregnancy, genetic information, disability, medical condition, marital status, sexual orientation, gender identity or expression, military or veteran status, or other unlawful factors. Gen prohibits discrimination based on these protected characteristics and recruits talented candidates from diverse backgrounds.\n\nWe consider individuals with arrest and conviction records and do not discriminate against employees for discussing their own pay or that of other employees or applicants. Learn more about pay transparency.\n\nTo conform to U.S. export control regulations, applicant should be eligible for any required authorizations from the U.S. Government.",
         "6/30/2025, 3:27:17 AM"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub Category</th>\n",
       "      <th>Job Link</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Saved At</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Holman</td>\n",
       "      <td>Business Intelligence Developer II</td>\n",
       "      <td>BIE</td>\n",
       "      <td>Risky</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4259283922/...</td>\n",
       "      <td>About the job\\n\\nHolman is a family-owned, glo...</td>\n",
       "      <td>6/30/2025, 2:26:31 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The College Board</td>\n",
       "      <td>Data Analyst, AWS Analytics</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Risky</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4259283160/...</td>\n",
       "      <td>About the job\\n\\nCollege Board - Technology Di...</td>\n",
       "      <td>6/30/2025, 2:29:17 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmTrust Financial Services, Inc.</td>\n",
       "      <td>Analytics Analyst II</td>\n",
       "      <td>BIE</td>\n",
       "      <td>Medium</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4257913602/...</td>\n",
       "      <td>About the job\\n\\nOverview\\n\\nAmTrust Financial...</td>\n",
       "      <td>6/30/2025, 2:40:56 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Montana Foundation</td>\n",
       "      <td>Programmer Analyst</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Low</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4255252626/...</td>\n",
       "      <td>About the job\\n\\nAt the University of Montana ...</td>\n",
       "      <td>6/30/2025, 3:08:14 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gen</td>\n",
       "      <td>Digital Product Analyst</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Medium</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4205437869/...</td>\n",
       "      <td>About the job\\n\\nAbout The Role\\n\\nWe are hiri...</td>\n",
       "      <td>6/30/2025, 3:27:17 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company                           Job Title  \\\n",
       "0                            Holman  Business Intelligence Developer II   \n",
       "1                 The College Board         Data Analyst, AWS Analytics   \n",
       "2  AmTrust Financial Services, Inc.                Analytics Analyst II   \n",
       "3  University of Montana Foundation                  Programmer Analyst   \n",
       "4                               Gen             Digital Product Analyst   \n",
       "\n",
       "  Category Sub Category                                           Job Link  \\\n",
       "0      BIE        Risky  https://www.linkedin.com/jobs/view/4259283922/...   \n",
       "1  Analyst        Risky  https://www.linkedin.com/jobs/view/4259283160/...   \n",
       "2      BIE       Medium  https://www.linkedin.com/jobs/view/4257913602/...   \n",
       "3  Analyst          Low  https://www.linkedin.com/jobs/view/4255252626/...   \n",
       "4  Analyst       Medium  https://www.linkedin.com/jobs/view/4205437869/...   \n",
       "\n",
       "                                     Job Description               Saved At  \n",
       "0  About the job\\n\\nHolman is a family-owned, glo...  6/30/2025, 2:26:31 AM  \n",
       "1  About the job\\n\\nCollege Board - Technology Di...  6/30/2025, 2:29:17 AM  \n",
       "2  About the job\\n\\nOverview\\n\\nAmTrust Financial...  6/30/2025, 2:40:56 AM  \n",
       "3  About the job\\n\\nAt the University of Montana ...  6/30/2025, 3:08:14 AM  \n",
       "4  About the job\\n\\nAbout The Role\\n\\nWe are hiri...  6/30/2025, 3:27:17 AM  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    xDF = pd.read_excel('jobs.xlsx', sheet_name = 'jobs') # alternatively can sheet_name = 0 (saying its first sheet in the workbook)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "xDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jobs':                               Company       Category Sub Category\n",
       " 0                              Holman            BIE        Risky\n",
       " 1                   The College Board        Analyst        Risky\n",
       " 2    AmTrust Financial Services, Inc.            BIE       Medium\n",
       " 3    University of Montana Foundation        Analyst          Low\n",
       " 4                                 Gen        Analyst       Medium\n",
       " ..                                ...            ...          ...\n",
       " 229                        Quartet AI  Data Engineer     moderate\n",
       " 230                               ATC        Analyst     moderate\n",
       " 231                               ICF        Analyst     moderate\n",
       " 232                             Huron  Data Engineer     moderate\n",
       " 233                             Huron        Analyst     moderate\n",
       " \n",
       " [234 rows x 3 columns],\n",
       " 'Sheet1':                                               Company Category Sub Category\n",
       " 0                                              Holman      BIE        Risky\n",
       " 1                                   The College Board  Analyst        Risky\n",
       " 2                    AmTrust Financial Services, Inc.      BIE       Medium\n",
       " 3                    University of Montana Foundation  Analyst          Low\n",
       " 4                                                 Gen  Analyst       Medium\n",
       " 5                                               Apple  Analyst     moderate\n",
       " 6                                               Apple      BIE       Medium\n",
       " 7   Gleaners Community Food Bank of Southeastern M...  Analyst          Low\n",
       " 8                                 BOND Brothers, Inc.      BIE        Risky\n",
       " 9                          Delta Dental of Washington  Analyst       Medium\n",
       " 10                                          Timescale  Analyst          Low\n",
       " 11    Senior Analyst, Product Analytics (Remote - US)  Analyst      Mediuma\n",
       " 12                       FP&A Analyst, Consumer & Ads  Analyst        Risky\n",
       " 13                                     2020 Companies  Analyst     moderate}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    xDF_new = pd.read_excel(\n",
    "        'jobs.xlsx',\n",
    "        sheet_name = [                                           # multiple sheets can be brought in like a dict of DataFrames\n",
    "            'jobs',\n",
    "            'Sheet1'\n",
    "            ],\n",
    "        # engine = 'openpyxl',                                   # openpyxl is default. 'xlrd' for xls file. 'pyxlsb' for .xlsb file\n",
    "        usecols = ['Company', 'Category', 'Sub Category'],       # usecols - same as read_csv()\n",
    "        # header = 0,                                            # sometimes header might be row 2 as excel format weird\n",
    "        # skiprows = 0,                                          # skip top rows where some formatting or metadata exists\n",
    "        # skipfooter = 0                                         # excels comes with signatures, so to skip them\n",
    "        ) # all sheets\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "xDF_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use same best practices used in read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sub Category",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8e4b6c50-cdba-47d2-a730-d317b95ecee5",
       "rows": [
        [
         "0",
         "Holman",
         "BIE",
         "Risky"
        ],
        [
         "1",
         "The College Board",
         "Analyst",
         "Risky"
        ],
        [
         "2",
         "AmTrust Financial Services, Inc.",
         "BIE",
         "Medium"
        ],
        [
         "3",
         "University of Montana Foundation",
         "Analyst",
         "Low"
        ],
        [
         "4",
         "Gen",
         "Analyst",
         "Medium"
        ],
        [
         "5",
         "Apple",
         "Analyst",
         "moderate"
        ],
        [
         "6",
         "Apple",
         "BIE",
         "Medium"
        ],
        [
         "7",
         "Gleaners Community Food Bank of Southeastern Michigan",
         "Analyst",
         "Low"
        ],
        [
         "8",
         "BOND Brothers, Inc.",
         "BIE",
         "Risky"
        ],
        [
         "9",
         "Delta Dental of Washington",
         "Analyst",
         "Medium"
        ],
        [
         "10",
         "Timescale",
         "Analyst",
         "Low"
        ],
        [
         "11",
         "Senior Analyst, Product Analytics (Remote - US)",
         "Analyst",
         "Mediuma"
        ],
        [
         "12",
         "FP&A Analyst, Consumer & Ads",
         "Analyst",
         "Risky"
        ],
        [
         "13",
         "2020 Companies",
         "Analyst",
         "moderate"
        ],
        [
         "14",
         "Royal Caribbean Group",
         "Analyst",
         "moderate"
        ],
        [
         "15",
         "Abott",
         "Analyst",
         "Risky"
        ],
        [
         "16",
         "Abott",
         "Analyst",
         "Risky"
        ],
        [
         "17",
         "Abott",
         "Analyst",
         "Risky"
        ],
        [
         "18",
         "Posit PBC",
         "Analyst",
         "Risky"
        ],
        [
         "19",
         "DoorDash",
         "Analyst",
         "Risky"
        ],
        [
         "20",
         "Affirma",
         "Analyst",
         "safe"
        ],
        [
         "21",
         "Equifax",
         "Analyst",
         "moderate"
        ],
        [
         "22",
         "Charles River Associates",
         "Analyst",
         "moderate"
        ],
        [
         "23",
         "Hayden AI",
         "Analyst",
         "moderate"
        ],
        [
         "24",
         "Boston Globe Media",
         "BIE",
         "moderate"
        ],
        [
         "25",
         "Sally Beauty Holdings",
         "BIE",
         "moderate"
        ],
        [
         "26",
         "Seismic",
         "BIE",
         "moderate"
        ],
        [
         "27",
         "Health Monitor Network",
         "BIE",
         "moderate"
        ],
        [
         "28",
         "International SOS",
         "Analyst",
         "low"
        ],
        [
         "29",
         "Ezee Fiber",
         "BIE",
         "moderate"
        ],
        [
         "30",
         "Insight Global",
         "BIE",
         "moderate"
        ],
        [
         "31",
         "Flywheel",
         "BIE",
         "moderate"
        ],
        [
         "32",
         "Apex Systems",
         "Analyst",
         "safe"
        ],
        [
         "33",
         "Industrial Electric Mfg. (IEM)",
         "BIE",
         "safe"
        ],
        [
         "34",
         "Packsize",
         "BIE",
         "moderate"
        ],
        [
         "35",
         "Henry Schein One",
         "Analyst",
         "moderate"
        ],
        [
         "36",
         "Piper Companies",
         "Analyst",
         "Risky"
        ],
        [
         "37",
         "Alera Group, Inc.",
         "Analyst",
         "Risky"
        ],
        [
         "38",
         "CBRE",
         "Analyst",
         "Risky"
        ],
        [
         "39",
         "Healthcare.com",
         "Analyst",
         "Risky"
        ],
        [
         "40",
         "Rivian",
         "BIE",
         "Risky"
        ],
        [
         "41",
         "Vontier",
         "Analyst",
         "moderate"
        ],
        [
         "42",
         "AssetWatch¬Æ",
         "BIE",
         "safe"
        ],
        [
         "43",
         "MyFitnessPal",
         "BIE",
         "moderate"
        ],
        [
         "44",
         "Truist",
         "Analyst",
         "Risky"
        ],
        [
         "45",
         "Bain & Company",
         "Analyst",
         "moderate"
        ],
        [
         "46",
         "Acosta",
         "Analyst",
         "safe"
        ],
        [
         "47",
         "Acosta",
         "Analyst",
         "Risky"
        ],
        [
         "48",
         "PNC",
         "Analyst",
         "Risky"
        ],
        [
         "49",
         "Arrowmac",
         "Analyst",
         "safe"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 234
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Holman</td>\n",
       "      <td>BIE</td>\n",
       "      <td>Risky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The College Board</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Risky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmTrust Financial Services, Inc.</td>\n",
       "      <td>BIE</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Montana Foundation</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gen</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Quartet AI</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>ATC</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>ICF</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Huron</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Huron</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Company       Category Sub Category\n",
       "0                              Holman            BIE        Risky\n",
       "1                   The College Board        Analyst        Risky\n",
       "2    AmTrust Financial Services, Inc.            BIE       Medium\n",
       "3    University of Montana Foundation        Analyst          Low\n",
       "4                                 Gen        Analyst       Medium\n",
       "..                                ...            ...          ...\n",
       "229                        Quartet AI  Data Engineer     moderate\n",
       "230                               ATC        Analyst     moderate\n",
       "231                               ICF        Analyst     moderate\n",
       "232                             Huron  Data Engineer     moderate\n",
       "233                             Huron        Analyst     moderate\n",
       "\n",
       "[234 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xDF_new['jobs']                     # use this to get specific dataframe from the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Company       Category Sub Category\n",
      "0                              Holman            BIE        Risky\n",
      "1                   The College Board        Analyst        Risky\n",
      "2    AmTrust Financial Services, Inc.            BIE       Medium\n",
      "3    University of Montana Foundation        Analyst          Low\n",
      "4                                 Gen        Analyst       Medium\n",
      "..                                ...            ...          ...\n",
      "229                        Quartet AI  Data Engineer     moderate\n",
      "230                               ATC        Analyst     moderate\n",
      "231                               ICF        Analyst     moderate\n",
      "232                             Huron  Data Engineer     moderate\n",
      "233                             Huron        Analyst     moderate\n",
      "\n",
      "[234 rows x 3 columns]\n",
      "                                              Company Category Sub Category\n",
      "0                                              Holman      BIE        Risky\n",
      "1                                   The College Board  Analyst        Risky\n",
      "2                    AmTrust Financial Services, Inc.      BIE       Medium\n",
      "3                    University of Montana Foundation  Analyst          Low\n",
      "4                                                 Gen  Analyst       Medium\n",
      "5                                               Apple  Analyst     moderate\n",
      "6                                               Apple      BIE       Medium\n",
      "7   Gleaners Community Food Bank of Southeastern M...  Analyst          Low\n",
      "8                                 BOND Brothers, Inc.      BIE        Risky\n",
      "9                          Delta Dental of Washington  Analyst       Medium\n",
      "10                                          Timescale  Analyst          Low\n",
      "11    Senior Analyst, Product Analytics (Remote - US)  Analyst      Mediuma\n",
      "12                       FP&A Analyst, Consumer & Ads  Analyst        Risky\n",
      "13                                     2020 Companies  Analyst     moderate\n"
     ]
    }
   ],
   "source": [
    "for sheets, df in xDF_new.items():\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.from_records?                        # nice method, but not needed -- pd.DataFrame() does all this does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### » read_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived     Sex   Age  Pclass\n",
      "0              3         1  female  26.0       3\n",
      "1              9         1  female  27.0       3\n",
      "2             10         1  female  14.0       2\n",
      "3             11         1  female   4.0       3\n",
      "4             23         1  female  15.0       3\n",
      "..           ...       ...     ...   ...     ...\n",
      "151          875         1  female  28.0       2\n",
      "152          876         1  female  15.0       3\n",
      "153          881         1  female  25.0       2\n",
      "154          888         1  female  19.0       1\n",
      "155          890         1    male  26.0       1\n",
      "\n",
      "[156 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "parqDF = pd.read_parquet(\n",
    "            path = 'titanic.parquet',\n",
    "            engine = 'pyarrow',                  # default is auto == pyarrow, it thats n/a then fastparquet gets chosen \n",
    "            columns = ['PassengerId', 'Survived', 'Sex', 'Age', 'Pclass'],          # filter by columns\n",
    "            filters = [\n",
    "                ('Survived', '==', 1),\n",
    "                ('Age', '<', 30)                        # engine=\"pyarrow\" also needed to be specified for filter to work\n",
    "                ]                                       # filter by row values, ( ==, =, !=, <, <=, >, >=, in, not in)\n",
    "        )   \n",
    "\n",
    "print(parqDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### » read_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(postgresql://toofanmacpro@localhost:5432/testdb) created\n",
      "\n",
      "read success\n",
      "   index  id  salary\n",
      "0      0   1     100\n",
      "1      1   2     200\n",
      "2      2   3     300\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "try:\n",
    "    engine = create_engine('postgresql://toofanmacpro@localhost:5432/testdb')\n",
    "    print(engine,f\"created\\n\")\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql('SELECT * FROM \"Employee\";', connection)\n",
    "        print(\"read success\")\n",
    "        print(df)\n",
    "        connection.close()\n",
    "except Exception as e:\n",
    "    print(f\"error occurred {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(postgresql://toofanmacpro@localhost:5432/testdb) created\n",
      "\n",
      "   index  id  salary\n",
      "0      0   1     100\n",
      "1      1   2     200\n",
      "2      2   3     300\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    engine = create_engine('postgresql://toofanmacpro@localhost:5432/testdb')\n",
    "    print(engine, f\"created\\n\")\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        df_table = pd.read_sql_table('Employee', connection)\n",
    "        print(df_table)\n",
    "        connection.close()\n",
    "except Exception as e:\n",
    "    print(f\"error occurred {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
